\documentclass{beamer}
% \usetheme{metropolis}
\usetheme{Boadilla}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{tabularx} % Adicionado para tabelas ajustáveis
\usepackage{booktabs}  % Para linhas horizontais de qualidade
\usepackage{listings}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usetikzlibrary{shapes.geometric, arrows}
\lstset{basicstyle=\ttfamily\small, breaklines=true}
\usetikzlibrary{calc}
\usetikzlibrary{positioning, arrows.meta, shapes.geometric} % Para posicionamento, setas e formas
\usepackage{amsfonts}   % Para fontes matemáticas adicionais, se necessário
% \usetheme{Madrid} % Você pode escolher outro tema que preferir
\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm,text centered, draw=black, fill=gray!20]
\tikzstyle{process} = [rectangle, minimum width=2.5cm, minimum height=1cm, text centered, draw=black, fill=orange!20]
\tikzstyle{decision} = [diamond, aspect=2, minimum width=2.5cm, minimum height=1cm, text centered, draw=black, fill=green!20]
\tikzstyle{arrow} = [thick,->,>=stealth]

\lstset{
  language=Python,
  basicstyle=\ttfamily\footnotesize,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  showstringspaces=false,
  columns=fullflexible,
  keepspaces=true,
  numbers=left,
  numberstyle=\tiny\color{gray},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4,
}

\lstset{
    inputencoding=utf8,
    extendedchars=true,
    literate=
    {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
    {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
    {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
    {À}{{\`A}}1 {È}{{\`E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
    {ã}{{\~a}}1 {õ}{{\~o}}1
    {Ã}{{\~A}}1 {Õ}{{\~O}}1
    {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
    {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
    {ç}{{\c c}}1 {Ç}{{\c C}}1
    {ü}{{\"u}}1 {Ü}{{\"U}}1
}

\title{Aprendizado Não Supervisionado (Aula 01)}
\author{Nator Junior C. Costa}
\date{\today}

\begin{document}

\frame{\titlepage}




\begin{frame}{Introdução ao Aprendizado Não Supervisionado}
    \begin{itemize}
        \item \textbf{Definição:} 
        \begin{itemize}
            \item Método de aprendizado de máquina que identifica padrões e estruturas em dados sem rótulos pré-definidos.
        \end{itemize}
        \item \textbf{Objetivo:}
        \begin{itemize}
            \item Descobrir a estrutura subjacente dos dados.
            \item Agrupar dados semelhantes.
            \item Reduzir a dimensionalidade dos dados para facilitar a visualização e interpretação.
        \end{itemize}
    \end{itemize}
\end{frame}



\begin{frame}{Diferenças}
    \scriptsize % Reduz ainda mais o tamanho da fonte

    \begin{tabularx}{\textwidth}{>{\raggedright\arraybackslash}p{3cm} 
                                   >{\raggedright\arraybackslash}p{4cm} 
                                   >{\raggedright\arraybackslash}p{4cm}}
        \toprule
        \textbf{Característica} & \textbf{Supervisionado} & \textbf{Não Supervisionado} \\
        \midrule
        Dados & 
        \begin{itemize}
            \item Rotulados
        \end{itemize} & 
        \begin{itemize}
            \item Não rotulados
        \end{itemize} \\
        
        Objetivo & 
        \begin{itemize}
            \item Previsão
            \item Classificação
        \end{itemize} & 
        \begin{itemize}
            \item Descoberta de padrões
            \item Estruturação de dados
        \end{itemize} \\
        
        Exemplos de Algoritmos & 
        \begin{itemize}
            \item Regressão
            \item Árvores de Decisão
            \item SVM
        \end{itemize} & 
        \begin{itemize}
            \item K-Means
            \item PCA
            \item DBSCAN
        \end{itemize} \\
        \bottomrule
    \end{tabularx}
    
    \vspace{0.3cm}
    
    \textbf{Quando Usar:}
    \begin{itemize}
        \item \textbf{Supervisionado:} Quando há dados rotulados disponíveis.
        \item \textbf{Não Supervisionado:} Quando não há rótulos e deseja-se explorar a estrutura dos dados.
    \end{itemize}
\end{frame}






\begin{frame}{Aplicações e Exemplos de Aprendizado Não Supervisionado}
    \textbf{Principais Aplicações:}
    \begin{itemize}
        \item \textbf{Clustering (Agrupamento):} Identificação de grupos semelhantes dentro dos dados.
        \item \textbf{Redução de Dimensionalidade:} Simplificação dos dados mantendo as informações essenciais.
        \item \textbf{Detecção de Anomalias:} Identificação de padrões ou pontos de dados que diferem significativamente dos demais.
        \item \textbf{Regras de Associação:} Descoberta de relações entre variáveis nos dados.
    \end{itemize}
    
    % \vspace{0.5cm}
    
    % \textbf{Exemplos de Algoritmos:}
    % \begin{itemize}
    %     \item \textbf{K-Means:} Algoritmo de agrupamento que divide os dados em K clusters.
    %     \item \textbf{PCA (Análise de Componentes Principais):} Técnica de redução de dimensionalidade.
    %     \item \textbf{DBSCAN (Density-Based Spatial Clustering of Applications with Noise):} Algoritmo de clustering baseado em densidade.
    %     \item \textbf{Autoencoders:} Redes neurais utilizadas para redução de dimensionalidade e aprendizado de representações.
    % \end{itemize}
\end{frame}


\begin{frame}[fragile]{Aprendizagem Supervisionada}
    \begin{itemize}
        \item A \textbf{aprendizagem supervisionada} utiliza um conjunto de dados rotulados para ensinar o modelo a prever saídas \textbf{y} com base em entradas \textbf{X}.
        \item Cada exemplo no conjunto de dados é um par \textbf{(X, y)}, onde:
        \begin{itemize}
            \item \textbf{X}: Conjunto de características (por exemplo, idade, altura, etc.).
            \item \textbf{y}: Rótulo ou resultado esperado (por exemplo, categoria, classe, etc.).
        \end{itemize}
        \item O objetivo é treinar um modelo para aprender a relação entre \textbf{X} e \textbf{y}, de forma a generalizar para novos dados.
    \end{itemize}
    
    \vspace{0.5cm}
    
    % \begin{tikzpicture}[node distance=2.5cm, every node/.style={scale=1}]
    %     % Definindo nós com cores
    %     \node (input) [draw, fill=blue!20, rectangle, minimum width=3.5cm, minimum height=1.5cm] {Conjunto de Dados \\ $\mathbf{X}$};
    %     \node (model) [draw, fill=green!20, rectangle, right of=input, minimum width=3.5cm, minimum height=1.5cm, xshift=1.5cm] {Modelo \\ $f(\mathbf{X})$};
    %     \node (output) [draw, fill=orange!20, rectangle, right of=model, minimum width=3.5cm, minimum height=1.5cm, xshift=1.5cm] {Previsão \\ $\hat{y}$};
        
    %     % Desenhando setas com rótulos
    %     \draw[->, thick] (input) -- (model) node[midway, above] {Treinamento};
    %     \draw[->, thick] (model) -- (output) node[midway, above] {Previsão};
        
    %     % Adicionando descrições abaixo dos nós
    %     \node at ($(input.south)!0.5!(model.south) - (0,0.8)$) {Dados de entrada (características)};
    %     \node at ($(model.south)!0.5!(output.south) - (0,0.8)$) {Função aprendida pelo modelo};
    %     \node at (output.south) [below=0.8cm] {Resultado previsto ($\hat{y}$)};
    % \end{tikzpicture}
    
\end{frame}


\begin{frame}{Aprendizagem Supervisionada}
    \begin{itemize}
        \item \textbf{Dados:} Conjunto de pares \(\{ (\mathbf{x}_1, y_1), (\mathbf{x}_2, y_2), \dots, (\mathbf{x}_n, y_n) \}\), onde:
        \begin{itemize}
            \item \(\mathbf{x}_i \in \mathbb{R}^d\): Vetor de características (e.g., idade, altura).
            \item \(y_i\): Rótulo ou saída esperada (e.g., classe, valor numérico).
        \end{itemize}
        \item \textbf{Objetivo:} Encontrar uma função \(f: \mathbb{R}^d \rightarrow \mathbb{R}\) tal que \(f(\mathbf{x}_i) \approx y_i\).
    \end{itemize}
    
    \vspace{0.5cm}
    
    \begin{center}
        \begin{tikzpicture}[node distance=2.5cm]
            % Input Node
            \node (input) [draw, fill=blue!20, rectangle, minimum width=2.5cm, minimum height=1cm] {Entradas  \(\mathbf{X}\)};
            % Model Node
            \node (model) [draw, fill=green!20, rectangle, right of=input, xshift=2cm, minimum width=2.5cm, minimum height=1cm] {Modelo \(f(\mathbf{X})\)};
            % Output Node
            \node (output) [draw, fill=orange!20, rectangle, right of=model, xshift=2cm, minimum width=2.5cm, minimum height=1cm] {Saída \(\hat{y}\)};
            % Arrows
            \draw[->, thick] (input) -- (model) node[midway, above] {};
            \draw[->, thick] (model) -- (output) node[midway, above] {};
            % Labels
            \node at ($(input.east)!0.5!(model.west)$) [above] {Treinamento};
            \node at ($(model.east)!0.5!(output.west)$) [above] {Previsão};
        \end{tikzpicture}
    \end{center}
\end{frame}


% \begin{frame}{Aprendizagem Não Supervisionada}
%     \begin{itemize}
%         \item Na aprendizagem não supervisionada, temos somente o vetor \textbf{X}.
%         \item Nesse caso, o objetivo é descobrir alguma coisa a respeito dos dados.
%         \begin{itemize}
%             \item Por exemplo, como eles estão agrupados.
%         \end{itemize}
%         \item A aprendizagem não supervisionada é mais subjetiva que a supervisionada, pois não há um objetivo simples como a classificação.
%     \end{itemize}
% \end{frame}


% \begin{frame}{Aprendizagem Não Supervisionada}
%     \begin{itemize}
%         \item \textbf{Dados:} Conjunto de vetores \(\{\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_n\}\), com \(\mathbf{x}_i \in \mathbb{R}^d\).
%         \item \textbf{Objetivo:} Descobrir estruturas ocultas sem rótulos.
%         \item \textbf{Exemplos:}
%         \begin{itemize}
%             \item \textbf{Clustering}
%                 \begin{itemize}
%                     \item Agrupamento de dados similares.
%                     \item
%                     \begin{center}
%                         \begin{tikzpicture}[scale=0.8]
%                             % Cluster 1
%                             \fill[red] (0,0) circle (0.1);
%                             \fill[red] (0.3,0.2) circle (0.1);
%                             \fill[red] (-0.2,0.1) circle (0.1);
%                             % Cluster 2
%                             \fill[blue] (2,2) circle (0.1);
%                             \fill[blue] (2.2,1.8) circle (0.1);
%                             \fill[blue] (1.8,2.1) circle (0.1);
%                             % Circles around clusters
%                             \draw[red, thick] (0.03,0.1) circle (0.5);
%                             \draw[blue, thick] (2,2) circle (0.5);
%                         \end{tikzpicture}
%                     \end{center}
%                 \end{itemize}
%             \item \textbf{Redução de Dimensionalidade}
%                 \begin{itemize}
%                     \item Projeção em dimensões menores.
%                     \item
%                     \begin{center}
%                         \begin{tikzpicture}[scale=0.8]
%                             % Axes
%                             \draw[->] (0,0) -- (3,0) node[right] {$x_1$};
%                             \draw[->] (0,0) -- (0,2) node[above] {$x_2$};
%                             % Data points
%                             \fill (0.5,1.5) circle (0.07);
%                             \fill (1,1) circle (0.07);
%                             \fill (1.5,0.5) circle (0.07);
%                             % Principal Component
%                             \draw[->, dashed] (0,0) -- (2,2) node[right] {PC1};
%                             % Projection lines
%                             \draw[dashed] (0.5,1.5) -- (1,1);
%                             \draw[dashed] (1,1) -- (1.5,0.5);
%                         \end{tikzpicture}
%                     \end{center}
%                 \end{itemize}
%         \end{itemize}
%     \end{itemize}
% \end{frame}


% \begin{frame}{Dados Não Rotulados}
%     \begin{itemize}
%         \item \textbf{Dados não rotulados:}
%         \begin{itemize}
%             \item A obtenção de dados não rotulados não é custosa!
%         \end{itemize}
%     \end{itemize}
% \end{frame}

\begin{frame}{Aprendizagem Não Supervisionada}
    \begin{itemize}
        \item \textbf{Dados:} Conjunto de vetores \(\{\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_n\}\), onde \(\mathbf{x}_i \in \mathbb{R}^d\).
        \item \textbf{Objetivo:} Descobrir estruturas ocultas sem rótulos.
    \end{itemize}
    \vspace{0.5cm}
    \begin{columns}[T]
        \column{0.5\textwidth}
        \centering
        \textbf{Clustering}
        \begin{itemize}
            \item Agrupamento de dados similares.
        \end{itemize}
        \begin{tikzpicture}[scale=0.8]
            % Cluster 1
            \fill[red] (0,0) circle (0.1);
            \fill[red] (0.3,0.2) circle (0.1);
            \fill[red] (-0.2,0.1) circle (0.1);
            % Cluster 2
            \fill[blue] (2,2) circle (0.1);
            \fill[blue] (2.2,1.8) circle (0.1);
            \fill[blue] (1.8,2.1) circle (0.1);
            % Circles around clusters
            \draw[red, thick] (0.03,0.1) circle (0.5);
            \draw[blue, thick] (2,2) circle (0.5);
        \end{tikzpicture}
        \column{0.5\textwidth}
        \centering
        \textbf{Redução de Dimensionalidade}
        \begin{itemize}
            \item Projeção em dimensões menores.
        \end{itemize}
        \begin{tikzpicture}[scale=0.8]
            % Axes
            \draw[->] (0,0) -- (3,0) node[right] {$x_1$};
            \draw[->] (0,0) -- (0,2) node[above] {$x_2$};
            % Data points
            \fill (0.5,1.5) circle (0.07);
            \fill (1,1) circle (0.07);
            \fill (1.5,0.5) circle (0.07);
            % Principal Component
            \draw[->, dashed] (0,0) -- (2,2) node[right] {PC1};
            % Projection lines
            \draw[dashed] (0.5,1.5) -- (1,1);
            \draw[dashed] (1,1) -- (1.5,0.5);
        \end{tikzpicture}
    \end{columns}

    \begin{itemize}
        \item Na aprendizagem não supervisionada, temos somente o vetor \textbf{X}.
        \item Nesse caso, o objetivo é descobrir alguma coisa a respeito dos dados.
        \begin{itemize}
            \item Por exemplo, como eles estão agrupados.
        \end{itemize}
    \end{itemize}
\end{frame}


\begin{frame}
    \centering
    \huge
    Agrupamento (Clustering)
\end{frame}


% Frame: Agrupamento (Clustering)
\begin{frame}{Agrupamento (Clustering)}
    \begin{itemize}
        \item \textbf{Definição:} Método de aprendizagem não supervisionada que agrupa dados em clusters baseados em similaridades.
        \item \textbf{Objetivo:} Maximizar a homogeneidade dentro dos clusters e a heterogeneidade entre eles.
        \item \textbf{Aplicações:}
        \begin{itemize}
            % \item Segmentação de mercado
            \item Análise de imagens
            \item Agrupamento de documentos
        \end{itemize}
    \end{itemize}
    \vspace{0.5cm}
    \begin{center}
        \begin{tikzpicture}[scale=0.8]
            % Cluster 1
            \fill[red!70] (0,0) circle (0.1);
            \fill[red!70] (0.3,0.2) circle (0.1);
            \fill[red!70] (-0.2,0.1) circle (0.1);
            % Cluster 2
            \fill[blue!70] (2,2) circle (0.1);
            \fill[blue!70] (2.2,1.8) circle (0.1);
            \fill[blue!70] (1.8,2.1) circle (0.1);
            % Cluster 3
            \fill[green!70!black] (4,0) circle (0.1);
            \fill[green!70!black] (4.2,0.2) circle (0.1);
            \fill[green!70!black] (3.8,0.1) circle (0.1);
            % Circles around clusters
            \draw[red!70, thick] (0.03,0.1) circle (0.5);
            \draw[blue!70, thick] (2,2) circle (0.5);
            \draw[green!70!black, thick] (4,0.1) circle (0.5);
        \end{tikzpicture}
    \end{center}
\end{frame}

% % Frame: K-means - Introdução
% \begin{frame}{K-médias (K-means)}
%     \begin{itemize}
%         \item \textbf{Algoritmo de clustering} que particiona \(n\) observações em \(k\) clusters.
%         \item \textbf{Objetivo:} Minimizar a soma das distâncias quadráticas entre pontos e o centroide do cluster.
%     \end{itemize}
%     \vspace{0.5cm}
%     \begin{center}
%         \begin{tikzpicture}[scale=0.8]
%             % Data points
%             \foreach \i in {0,0.5,...,4} {
%                 \foreach \j in {0,0.5,...,4} {
%                     \fill[gray!50] (\i,\j) circle (0.05);
%                 }
%             }
%             % Initial centroids
%             \fill[red] (1,3) node[above] {C1} circle (0.15);
%             \fill[blue] (3,1) node[below] {C2} circle (0.15);
%         \end{tikzpicture}
%     \end{center}
% \end{frame}

% % Frame: K-means - Passo 1
% \begin{frame}{K-means: Passo 1 - Inicialização dos Centroides}
%     \begin{itemize}
%         \item Selecionar aleatoriamente \(k\) centroides iniciais.
%         \item \(k\) é o número de clusters desejados.
%     \end{itemize}
%     \vspace{0.5cm}
%     \begin{center}
%         \begin{tikzpicture}[scale=0.8]
%             % Data points
%             \foreach \i in {0,0.5,...,4} {
%                 \foreach \j in {0,0.5,...,4} {
%                     \fill[gray!50] (\i,\j) circle (0.05);
%                 }
%             }
%             % Initial centroids
%             \fill[red] (1,3) node[above] {C1} circle (0.15);
%             \fill[blue] (3,1) node[below] {C2} circle (0.15);
%         \end{tikzpicture}
%     \end{center}
% \end{frame}
% % Frame: K-means - Passo 2
% \begin{frame}{K-means: Passo 2 - Atribuição aos Clusters}
%     \begin{itemize}
%         \item Atribuir cada ponto de dados ao centroide mais próximo, com base na distância euclidiana.
%         \item Formar clusters iniciais baseados na proximidade.
%     \end{itemize}
%     \vspace{0.3cm}
%     \begin{center}
%         \begin{tikzpicture}[scale=0.9]
%             % Axes
%             \draw[->] (-0.5,0) -- (5,0) node[right] {$x$};
%             \draw[->] (0,-0.5) -- (0,5) node[above] {$y$};

%             % Initial centroids
%             \fill[red] (1,4) node[above] {C1} circle (0.12);
%             \fill[blue] (4,1) node[below] {C2} circle (0.12);

%             % Data points
%             \foreach \x/\y in {0.8/3.5,1.2/3.8,1/3,1.5/3.2} {
%                 \fill[black] (\x,\y) circle (0.08);
%                 \draw[dashed, red!70] (\x,\y) -- (1,4);
%             }
%             \foreach \x/\y in {3.8/1.5,4.2/1.2,3.5/1,4/0.8} {
%                 \fill[black] (\x,\y) circle (0.08);
%                 \draw[dashed, blue!70] (\x,\y) -- (4,1);
%             }
%             \foreach \x/\y in {2/2.5,2.5/2.8,2.2/2} {
%                 % Compute distances to centroids
%                 \pgfmathsetmacro{\distCOne}{sqrt((\x-1)^2+(\y-4)^2)}
%                 \pgfmathsetmacro{\distCTwo}{sqrt((\x-4)^2+(\y-1)^2)}
%                 % Decide which centroid is closer
%                 \ifdim \distCOne pt<\distCTwo pt
%                     \fill[black] (\x,\y) circle (0.08);
%                     \draw[dashed, red!70] (\x,\y) -- (1,4);
%                 \else
%                     \fill[black] (\x,\y) circle (0.08);
%                     \draw[dashed, blue!70] (\x,\y) -- (4,1);
%                 \fi
%             }
%         \end{tikzpicture}
%     \end{center}
% \end{frame}

% % Frame: K-means - Passo 3
% \begin{frame}{K-means: Passo 3 - Atualização dos Centroides}
%     \begin{itemize}
%         \item Recalcular a posição dos centroides como a média dos pontos atribuídos a cada cluster.
%     \end{itemize}
%     \vspace{0.3cm}
%     \begin{center}
%         \begin{tikzpicture}[scale=0.9]
%             % Axes
%             \draw[->] (-0.5,0) -- (5,0) node[right] {$x$};
%             \draw[->] (0,-0.5) -- (0,5) node[above] {$y$};

%             % Data points assigned to Cluster 1
%             \foreach \x/\y in {0.8/3.5,1.2/3.8,1/3,1.5/3.2,2/2.5,2.2/2} {
%                 \fill[red!70] (\x,\y) circle (0.08);
%             }
%             % Data points assigned to Cluster 2
%             \foreach \x/\y in {3.8/1.5,4.2/1.2,3.5/1,4/0.8,2.5/2.8} {
%                 \fill[blue!70] (\x,\y) circle (0.08);
%             }
%             % New centroids
%             \fill[red] (1.45,3.17) node[above] {C1'} circle (0.12);
%             \fill[blue] (3.6,1.46) node[below] {C2'} circle (0.12);
%             % Lines from data points to centroids (optional)
%         \end{tikzpicture}
%     \end{center}
% \end{frame}

% % Frame: K-means - Iteração
% \begin{frame}{K-means: Repetição até Convergência}
%     \begin{itemize}
%         \item Repetir os passos de atribuição e atualização até que os centroides não mudem significativamente.
%     \end{itemize}
%     \vspace{0.3cm}
%     \begin{center}
%         \begin{tikzpicture}[scale=0.9]
%             % Axes
%             \draw[->] (-0.5,0) -- (5,0) node[right] {$x$};
%             \draw[->] (0,-0.5) -- (0,5) node[above] {$y$};

%             % Updated centroids from previous step
%             \fill[red] (1.45,3.17) node[above] {C1'} circle (0.12);
%             \fill[blue] (3.6,1.46) node[below] {C2'} circle (0.12);

%             % Data points
%             \foreach \x/\y in {0.8/3.5,1.2/3.8,1/3,1.5/3.2,2/2.5,2.2/2,2.5/2.8,3.8/1.5,4.2/1.2,3.5/1,4/0.8} {
%                 % Compute distances to new centroids
%                 \pgfmathsetmacro{\distCOne}{sqrt((\x-1.45)^2+(\y-3.17)^2)}
%                 \pgfmathsetmacro{\distCTwo}{sqrt((\x-3.6)^2+(\y-1.46)^2)}
%                 % Decide which centroid is closer
%                 \ifdim \distCOne pt<\distCTwo pt
%                     \fill[red!70] (\x,\y) circle (0.08);
%                     \draw[dashed, red!70] (\x,\y) -- (1.45,3.17);
%                 \else
%                     \fill[blue!70] (\x,\y) circle (0.08);
%                     \draw[dashed, blue!70] (\x,\y) -- (3.6,1.46);
%                 \fi
%             }
%             % New centroids after this iteration (optional)
%         \end{tikzpicture}
%     \end{center}
% \end{frame}

% % Frame: K-means - Convergência
% \begin{frame}{K-means: Convergência}
%     \begin{itemize}
%         \item \textbf{Resultado Final:} Clusters definidos e centroides estáveis.
%         \item \textbf{Observação:} O resultado pode depender da inicialização dos centroides.
%     \end{itemize}
%     \vspace{0.3cm}
%     \begin{center}
%         \begin{tikzpicture}[scale=0.9]
%             % Axes
%             \draw[->] (-0.5,0) -- (5,0) node[right] {$x$};
%             \draw[->] (0,-0.5) -- (0,5) node[above] {$y$};

%             % Final centroids
%             \fill[red] (1.45,3.17) node[above] {C1} circle (0.12);
%             \fill[blue] (3.6,1.46) node[below] {C2} circle (0.12);

%             % Data points assigned to Cluster 1
%             \foreach \x/\y in {0.8/3.5,1.2/3.8,1/3,1.5/3.2,2/2.5,2.2/2} {
%                 \fill[red!70] (\x,\y) circle (0.08);
%             }
%             % Data points assigned to Cluster 2
%             \foreach \x/\y in {2.5/2.8,3.8/1.5,4.2/1.2,3.5/1,4/0.8} {
%                 \fill[blue!70] (\x,\y) circle (0.08);
%             }
%             % Optional: Draw cluster boundaries
%             % \draw[thick, red!70] plot [smooth cycle] coordinates {(0.5,3) (1,4) (2.5,3) (2,2)};
%             % \draw[thick, blue!70] plot [smooth cycle] coordinates {(3,0.5) (4.5,1) (3,2.5) (2.5,2.5)};
%         \end{tikzpicture}
%     \end{center}
% \end{frame}


% % Frame: K-médias (K-means) - Introdução
% \begin{frame}{K-médias (K-means)}
%     \begin{itemize}
%         \item \textbf{Definição:} Algoritmo de clustering que particiona \( n \) observações em \( k \) clusters, onde cada observação pertence ao cluster com o centroide mais próximo.
%         \item \textbf{Objetivo:} Minimizar a soma das distâncias quadráticas entre os pontos e o centroide do cluster.
%     \end{itemize}
%     \vspace{0.5cm}
%     \begin{center}
%         \begin{tikzpicture}[scale=0.8]
%             % Dados não rotulados
%             \foreach \x/\y in {0.5/3.5, 1/4, 1.5/3, 3/1, 3.5/0.5, 4/1.5, 2/2.5, 2.5/2, 2/1} {
%                 \fill[gray!70] (\x,\y) circle (0.08);
%             }
%             \node at (2,4.5) {Dados não rotulados};
%         \end{tikzpicture}
%     \end{center}
% \end{frame}

% % Frame: K-médias - Passo 1: Inicialização dos Centroides
% \begin{frame}{K-médias: Passo 1 - Inicialização dos Centroides}
%     \begin{itemize}
%         \item Selecionar aleatoriamente \( k \) centroides iniciais.
%         \item Neste exemplo, \( k = 2 \).
%     \end{itemize}
%     \vspace{0.3cm}
%     \begin{center}
%         \begin{tikzpicture}[scale=0.8]
%             % Dados não rotulados
%             \foreach \x/\y in {0.5/3.5, 1/4, 1.5/3, 3/1, 3.5/0.5, 4/1.5, 2/2.5, 2.5/2, 2/1} {
%                 \fill[gray!70] (\x,\y) circle (0.08);
%             }
%             % Centroides iniciais
%             \fill[red] (1,4) node[above] {C1} circle (0.12);
%             \fill[blue] (4,1.5) node[right] {C2} circle (0.12);
%         \end{tikzpicture}
%     \end{center}
% \end{frame}

% % Frame: K-médias - Passo 2: Atribuição aos Clusters
% \begin{frame}{K-médias: Passo 2 - Atribuição aos Clusters}
%     \begin{itemize}
%         \item Para cada ponto de dados, calcular a distância aos centroides.
%         \item Atribuir cada ponto ao cluster do centroide mais próximo.
%     \end{itemize}
%     \vspace{0.3cm}
%     \begin{center}
%         \only<1>{
%             % Mostrar distâncias para o primeiro ponto
%             \begin{tikzpicture}[scale=0.8]
%                 % Dados
%                 \foreach \x/\y in {1.5/3, 3/1, 3.5/0.5, 4/1.5, 2/2.5, 2.5/2, 2/1} {
%                     \fill[gray!70] (\x,\y) circle (0.08);
%                 }
%                 % Primeiro ponto
%                 \fill[gray!70] (0.5,3.5) circle (0.08);
%                 % Centroides
%                 \fill[red] (1,4) node[above] {C1} circle (0.12);
%                 \fill[blue] (4,1.5) node[right] {C2} circle (0.12);
%                 % Linhas de distância
%                 \draw[dashed, red!70] (0.5,3.5) -- (1,4);
%                 \draw[dashed, blue!70] (0.5,3.5) -- (4,1.5);
%             \end{tikzpicture}
%         }
%         \only<2>{
%             % Todos os pontos atribuídos
%             \begin{tikzpicture}[scale=0.8]
%                 % Pontos atribuídos ao Cluster 1
%                 \foreach \x/\y in {0.5/3.5,1/4,1.5/3,2/2.5} {
%                     \fill[red!70] (\x,\y) circle (0.08);
%                 }
%                 % Pontos atribuídos ao Cluster 2
%                 \foreach \x/\y in {3/1,3.5/0.5,4/1.5,2.5/2,2/1} {
%                     \fill[blue!70] (\x,\y) circle (0.08);
%                 }
%                 % Centroides
%                 \fill[red] (1,4) node[above] {C1} circle (0.12);
%                 \fill[blue] (4,1.5) node[right] {C2} circle (0.12);
%             \end{tikzpicture}
%         }
%     \end{center}
% \end{frame}

% % Frame: K-médias - Passo 3: Atualização dos Centroides
% \begin{frame}{K-médias: Passo 3 - Atualização dos Centroides}
%     \begin{itemize}
%         \item Recalcular a posição dos centroides como a média dos pontos atribuídos.
%     \end{itemize}
%     \vspace{0.3cm}
%     \begin{center}
%         \only<1>{
%             % Mostrar cálculo da média para o Cluster 1
%             \begin{tikzpicture}[scale=0.8]
%                 % Pontos atribuídos ao Cluster 1
%                 \foreach \x/\y in {0.5/3.5,1/4,1.5/3,2/2.5} {
%                     \fill[red!70] (\x,\y) circle (0.08);
%                 }
%                 % Centróide antigo
%                 \fill[red!50] (1,4) circle (0.12);
%                 % Centróide novo
%                 \fill[red] (1.25,3.25) node[above] {C1'} circle (0.12);
%                 % Linhas para cálculo da média (opcional)
%             \end{tikzpicture}
%         }
%         \only<2>{
%             % Novos centroides para ambos os clusters
%             \begin{tikzpicture}[scale=0.8]
%                 % Pontos atribuídos ao Cluster 1
%                 \foreach \x/\y in {0.5/3.5,1/4,1.5/3,2/2.5} {
%                     \fill[red!70] (\x,\y) circle (0.08);
%                 }
%                 % Pontos atribuídos ao Cluster 2
%                 \foreach \x/\y in {3/1,3.5/0.5,4/1.5,2.5/2,2/1} {
%                     \fill[blue!70] (\x,\y) circle (0.08);
%                 }
%                 % Novos centroides
%                 \fill[red] (1.25,3.25) node[above] {C1'} circle (0.12);
%                 \fill[blue] (3.0,1.2) node[right] {C2'} circle (0.12);
%             \end{tikzpicture}
%         }
%     \end{center}
% \end{frame}

% % Frame: K-médias - Iteração até Convergência
% \begin{frame}{K-médias: Repetição até Convergência}
%     \begin{itemize}
%         \item Repetir os passos de atribuição e atualização até que os centroides não mudem significativamente.
%     \end{itemize}
%     \vspace{0.3cm}
%     \begin{center}
%         \begin{tikzpicture}[scale=0.8]
%             \only<1>{
%                 % Iteração 2 - Nova atribuição
%                 % Pontos atribuídos ao Cluster 1
%                 \foreach \x/\y in {0.5/3.5,1/4,1.5/3,2/2.5,2.5/2} {
%                     \fill[red!70] (\x,\y) circle (0.08);
%                 }
%                 % Pontos atribuídos ao Cluster 2
%                 \foreach \x/\y in {3/1,3.5/0.5,4/1.5,2/1} {
%                     \fill[blue!70] (\x,\y) circle (0.08);
%                 }
%                 % Centroides
%                 \fill[red] (1.25,3.25) node[above] {C1'} circle (0.12);
%                 \fill[blue] (3.0,1.2) node[right] {C2'} circle (0.12);
%             }
%             \only<2>{
%                 % Iteração 3 - Nova atualização de centroides
%                 \begin{tikzpicture}[scale=0.8]
%                     % Pontos atribuídos ao Cluster 1
%                     \foreach \x/\y in {0.5/3.5,1/4,1.5/3,2/2.5,2.5/2} {
%                         \fill[red!70] (\x,\y) circle (0.08);
%                     }
%                     % Pontos atribuídos ao Cluster 2
%                     \foreach \x/\y in {3/1,3.5/0.5,4/1.5,2/1} {
%                         \fill[blue!70] (\x,\y) circle (0.08);
%                     }
%                     % Novos centroides
%                     \fill[red] (1.5,3.0) node[above] {C1''} circle (0.12);
%                     \fill[blue] (3.125,1.25) node[right] {C2''} circle (0.12);
%                 \end{tikzpicture}
%             }
%             \only<3>{
%                 % Verificar se os centroides mudaram significativamente
%                 % Como as mudanças são pequenas, pode-se considerar que convergiu
%                 \begin{tikzpicture}[scale=0.8]
%                     % Pontos atribuídos ao Cluster 1
%                     \foreach \x/\y in {0.5/3.5,1/4,1.5/3,2/2.5,2.5/2} {
%                         \fill[red!70] (\x,\y) circle (0.08);
%                     }
%                     % Pontos atribuídos ao Cluster 2
%                     \foreach \x/\y in {3/1,3.5/0.5,4/1.5,2/1} {
%                         \fill[blue!70] (\x,\y) circle (0.08);
%                     }
%                     % Centroides finais
%                     \fill[red] (1.5,3.0) node[above] {C1} circle (0.12);
%                     \fill[blue] (3.125,1.25) node[right] {C2} circle (0.12);
%                 \end{tikzpicture}
%             }
%         \end{tikzpicture}
%     \end{center}
% \end{frame}

% % Frame: K-médias - Resultado Final
% \begin{frame}{K-médias: Resultado Final}
%     \begin{itemize}
%         \item \textbf{Clusters definidos:} Os dados foram agrupados em \( k \) clusters baseados na similaridade.
%         \item \textbf{Centroides estáveis:} Os centroides não mudam significativamente entre as iterações.
%     \end{itemize}
%     \vspace{0.3cm}
%     \begin{center}
%         \begin{tikzpicture}[scale=0.8]
%             % Pontos atribuídos ao Cluster 1
%             \foreach \x/\y in {0.5/3.5,1/4,1.5/3,2/2.5,2.5/2} {
%                 \fill[red!70] (\x,\y) circle (0.08);
%             }
%             % Pontos atribuídos ao Cluster 2
%             \foreach \x/\y in {3/1,3.5/0.5,4/1.5,2/1} {
%                 \fill[blue!70] (\x,\y) circle (0.08);
%             }
%             % Centroides finais
%             \fill[red] (1.5,3.0) node[above] {C1} circle (0.12);
%             \fill[blue] (3.125,1.25) node[right] {C2} circle (0.12);
%             % Opcional: Desenhar limites dos clusters
%             % \draw[red, thick, dashed] (2.25,1.75) -- (2.25,3.5);
%             % \draw[blue, thick, dashed] (2.25,1.75) -- (4.5,1.75);
%         \end{tikzpicture}
%     \end{center}
% \end{frame}

% Frame: K-médias (K-means) - Introdução
\begin{frame}{K-médias (K-means)}
    \begin{itemize}
        \item \textbf{Definição:} Algoritmo que agrupa \( n \) observações em \( k \) clusters, onde cada observação pertence ao cluster com o centroide mais próximo.
        \item \textbf{Objetivo:} Minimizar a soma das distâncias quadráticas dentro dos clusters:
        \[
        \min_{\{C_j\}} \sum_{j=1}^{k} \sum_{\mathbf{x}_i \in C_j} \|\mathbf{x}_i - \boldsymbol{\mu}_j\|^2
        \]
        onde \( \boldsymbol{\mu}_j \) é o centroide do cluster \( C_j \).
    \end{itemize}
     \vspace{-0.5cm}
    \begin{center}
        \begin{tikzpicture}[scale=0.7]
            % Plano cartesiano fixo
            \draw[step=1cm,gray,very thin] (0,0) grid (5,5);
            \draw[->] (0,0) -- (5.2,0) node[right] {$x$};
            \draw[->] (0,0) -- (0,5.2) node[above] {$y$};

            % Dados não rotulados
            \foreach \x/\y in {%
                0.8/3.5,%
                1.2/4,%
                1.5/3,%
                2/2.5,%
                2/1,%
                2.5/2,%
                3/1,%
                3.5/0.8,%
                4/1.5%
            } {%
                \fill[gray!70] (\x,\y) circle (0.08);%
            }
        \end{tikzpicture}
    \end{center}
\end{frame}


% Frame: K-médias - Pseudocódigo (Parte 1)
\begin{frame}[fragile]{K-médias: Pseudocódigo}
    \textbf{Entrada:}
    \begin{itemize}
        \item Conjunto de dados: \( \{\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_n\} \)
        \item Número de clusters: \( k \)
    \end{itemize}
    \vspace{0.3cm}
    \textbf{Algoritmo:}
    \begin{lstlisting}[language=Python, mathescape=true]
1. Inicializar centroides $\boldsymbol{\mu}_1, \boldsymbol{\mu}_2, \dots, \boldsymbol{\mu}_k$ escolhendo $k$ pontos aleatórios do conjunto de dados.
    \end{lstlisting}
    \vspace{0.3cm}
    \textbf{Repetir até convergência:}
    \begin{lstlisting}[language=Python, mathescape=true]
2. Para cada ponto $\mathbf{x}_i$ do conjunto de dados:
       a) Calcular a distância entre $\mathbf{x}_i$ e cada centroide $\boldsymbol{\mu}_j$.
       b) Atribuir $\mathbf{x}_i$ ao cluster $C_j$ com o centroide mais próximo.
    \end{lstlisting}
\end{frame}

% Frame: K-médias - Pseudocódigo (Parte 2)
\begin{frame}[fragile]{K-médias: Pseudocódigo (continuação)}
    \textbf{Continuando o algoritmo:}
    \begin{lstlisting}[language=Python, mathescape=true]
3. Para cada cluster $C_j$:
       a) Atualizar o centroide $\boldsymbol{\mu}_j$ calculando a média dos pontos atribuídos ao cluster:
          $\boldsymbol{\mu}_j = \frac{1}{|C_j|} \sum_{\mathbf{x}_i \in C_j} \mathbf{x}_i$
    \end{lstlisting}
    \vspace{0.3cm}
    \textbf{Condição de Parada:}
    \begin{itemize}
        \item O algoritmo para quando os centroides não mudam significativamente entre as iterações, ou após um número máximo de iterações.
    \end{itemize}
    \vspace{0.3cm}
    \textbf{Saída:}
    \begin{itemize}
        \item Clusters \( C_1, C_2, \dots, C_k \) com seus respectivos centroides \( \boldsymbol{\mu}_1, \boldsymbol{\mu}_2, \dots, \boldsymbol{\mu}_k \).
    \end{itemize}
\end{frame}

% % Frame: K-médias - Explicação do Pseudocódigo
% \begin{frame}{K-médias: Explicação do Pseudocódigo}
%     \begin{itemize}
%         \item \textbf{Inicialização:} A escolha inicial dos centroides pode influenciar o resultado final. Uma boa prática é executar o algoritmo várias vezes com diferentes inicializações.
%         \item \textbf{Atribuição de Pontos:} Utiliza a distância euclidiana para determinar a proximidade aos centroides.
%         \item \textbf{Atualização dos Centroides:} Calcula a média aritmética dos pontos em cada cluster para encontrar o novo centroide.
%         \item \textbf{Convergência:} O algoritmo geralmente converge rapidamente, mas pode parar em um mínimo local.
%         % \item \textbf{Complexidade Computacional:} É proporcional ao número de pontos vezes o número de clusters e o número de iterações.
%     \end{itemize}
% \end{frame}


% Frame: Detalhamento das Funções no Pseudocódigo
\begin{frame}[fragile]{Detalhamento das Funções}
    \textbf{Cálculo da Distância Euclidiana:}
    \begin{equation*}
    d(\mathbf{x}_i, \boldsymbol{\mu}_j) = \sqrt{\sum_{l=1}^{m} (x_{il} - \mu_{jl})^2}
    \end{equation*}
    onde \( m \) é o número de características.

    \vspace{0.5cm}

    \textbf{Atualização dos Centroides:}
    \begin{equation*}
    \boldsymbol{\mu}_j = \frac{1}{|C_j|} \sum_{\mathbf{x}_i \in C_j} \mathbf{x}_i
    \end{equation*}

    \vspace{0.5cm}

    \textbf{Critério de Convergência:}
    \begin{itemize}
        \item Pode ser definido por um limiar \( \epsilon \) tal que:
        \[
        \max_j \|\boldsymbol{\mu}_j^{(t)} - \boldsymbol{\mu}_j^{(t-1)}\| < \epsilon
        \]
        \item Ou fixar um número máximo de iterações.
    \end{itemize}
\end{frame}









% Frame: K-médias - Passo 1: Inicialização dos Centroides
\begin{frame}{K-médias: Passo 1 - Inicialização dos Centroides}
    \begin{itemize}
        \item \textbf{Passo 1:} Selecionar aleatoriamente \( k \) centroides iniciais \( \boldsymbol{\mu}_1, \boldsymbol{\mu}_2 \).
        \item Neste exemplo, \( k = 2 \).
    \end{itemize}
    \vspace{0.3cm}
    \begin{center}
        \begin{tikzpicture}[scale=0.9]
            % Plano cartesiano fixo
            \draw[step=1cm,gray,very thin] (0,0) grid (5,5);
            \draw[->] (0,0) -- (5.2,0) node[right] {$x$};
            \draw[->] (0,0) -- (0,5.2) node[above] {$y$};

            % Dados
            \foreach \x/\y in {%
                0.8/3.5,%
                1.2/4,%
                1.5/3,%
                2/2.5,%
                2/1,%
                2.5/2,%
                3/1,%
                3.5/0.8,%
                4/1.5%
            } {%
                \fill[gray!70] (\x,\y) circle (0.08);%
            }
            % Centroides iniciais
            \fill[red] (1,4) node[above] {\(\boldsymbol{\mu}_1\)} circle (0.12);
            \fill[blue] (4,1.5) node[right] {\(\boldsymbol{\mu}_2\)} circle (0.12);
        \end{tikzpicture}
    \end{center}
\end{frame}

% Frame: K-médias - Passo 2: Atribuição aos Clusters
\begin{frame}{K-médias: Passo 2 - Atribuição aos Clusters}
    \begin{itemize}
        \item \textbf{Passo 2:} Atribuir cada ponto \( \mathbf{x}_i \) ao cluster com o centroide mais próximo:
        \[
        c_i = \arg\min_{j} \|\mathbf{x}_i - \boldsymbol{\mu}_j\|^2
        \]
    \end{itemize}
    \vspace{0.3cm}
    \begin{center}
        \begin{tikzpicture}[scale=0.9]
            % Plano cartesiano fixo
            \draw[step=1cm,gray,very thin] (0,0) grid (5,5);
            \draw[->] (0,0) -- (5.2,0) node[right] {$x$};
            \draw[->] (0,0) -- (0,5.2) node[above] {$y$};

            % Centroides
            \fill[red] (1,4) node[above] {\(\boldsymbol{\mu}_1\)} circle (0.12);
            \fill[blue] (4,1.5) node[right] {\(\boldsymbol{\mu}_2\)} circle (0.12);

            % Dados atribuídos e linhas de conexão
            \foreach \x/\y/\c/\mx/\my in {%
                0.8/3.5/red/1/4,%
                1.2/4/red/1/4,%
                1.5/3/red/1/4,%
                2/2.5/red/1/4,%
                2/1/blue/4/1.5,%
                2.5/2/blue/4/1.5,%
                3/1/blue/4/1.5,%
                3.5/0.8/blue/4/1.5,%
                4/1.5/blue/4/1.5%
            } {%
                \fill[\c!70] (\x,\y) circle (0.08);%
                \draw[dashed, \c!50] (\x,\y) -- (\mx,\my);%
            }
        \end{tikzpicture}
    \end{center}
\end{frame}

% Frame: K-médias - Passo 3: Atualização dos Centroides
\begin{frame}{K-médias: Passo 3 - Atualização dos Centroides}
    \begin{itemize}
        \item \textbf{Passo 3:} Atualizar os centroides calculando a média dos pontos atribuídos:
        \[
        \boldsymbol{\mu}_j = \frac{1}{|C_j|} \sum_{\mathbf{x}_i \in C_j} \mathbf{x}_i
        \]
    \end{itemize}
    \vspace{0.3cm}
    \begin{center}
        \begin{tikzpicture}[scale=0.9]
            % Plano cartesiano fixo
            \draw[step=1cm,gray,very thin] (0,0) grid (5,5);
            \draw[->] (0,0) -- (5.2,0) node[right] {$x$};
            \draw[->] (0,0) -- (0,5.2) node[above] {$y$};

            % Dados atribuídos
            \foreach \x/\y/\c in {%
                0.8/3.5/red,%
                1.2/4/red,%
                1.5/3/red,%
                2/2.5/red,%
                2/1/blue,%
                2.5/2/blue,%
                3/1/blue,%
                3.5/0.8/blue,%
                4/1.5/blue%
            } {%
                \fill[\c!70] (\x,\y) circle (0.08);%
            }

            % Centroides atualizados
            \fill[red] (1.375,3.125) node[above] {\(\boldsymbol{\mu}_1'\)} circle (0.12);
            \fill[blue] (3.2,1.16) node[right] {\(\boldsymbol{\mu}_2'\)} circle (0.12);

            % Linhas de atualização
            \draw[->, red!70] (1,4) -- (1.375,3.125);
            \draw[->, blue!70] (4,1.5) -- (3.2,1.16);
        \end{tikzpicture}
    \end{center}
\end{frame}

% Frame: K-médias - Repetição dos Passos 2 e 3
\begin{frame}{K-médias: Repetição dos Passos 2 e 3}
    \begin{itemize}
        \item Repetir os passos de atribuição e atualização até a convergência.
    \end{itemize}
    \vspace{0.3cm}
    \begin{center}
        % Iteração 2
        \only<1>{
            \begin{tikzpicture}[scale=0.9]
                % Plano cartesiano fixo
                \draw[step=1cm,gray,very thin] (0,0) grid (5,5);
                \draw[->] (0,0) -- (5.2,0) node[right] {$x$};
                \draw[->] (0,0) -- (0,5.2) node[above] {$y$};

                % Centroides atualizados
                \fill[red] (1.375,3.125) node[above] {\(\boldsymbol{\mu}_1'\)} circle (0.12);
                \fill[blue] (3.2,1.16) node[right] {\(\boldsymbol{\mu}_2'\)} circle (0.12);

                % Dados atribuídos e linhas
                \foreach \x/\y/\c/\mx/\my in {%
                    0.8/3.5/red/1.375/3.125,%
                    1.2/4/red/1.375/3.125,%
                    1.5/3/red/1.375/3.125,%
                    2/2.5/red/1.375/3.125,%
                    2/1/blue/3.2/1.16,%
                    2.5/2/blue/3.2/1.16,%
                    3/1/blue/3.2/1.16,%
                    3.5/0.8/blue/3.2/1.16,%
                    4/1.5/blue/3.2/1.16%
                } {%
                    \fill[\c!70] (\x,\y) circle (0.08);%
                    \draw[dashed, \c!50] (\x,\y) -- (\mx,\my);%
                }
            \end{tikzpicture}
        }

        % Iteração 3
        \only<2>{
            \begin{tikzpicture}[scale=0.9]
                % Plano cartesiano fixo
                \draw[step=1cm,gray,very thin] (0,0) grid (5,5);
                \draw[->] (0,0) -- (5.2,0) node[right] {$x$};
                \draw[->] (0,0) -- (0,5.2) node[above] {$y$};

                % Centroides atualizados novamente
                \fill[red] (1.375,3.125) node[above] {\(\boldsymbol{\mu}_1\)} circle (0.12);
                \fill[blue] (3.2,1.16) node[right] {\(\boldsymbol{\mu}_2\)} circle (0.12);

                % Dados atribuídos (mesmos da iteração anterior)
                \foreach \x/\y/\c in {%
                    0.8/3.5/red,%
                    1.2/4/red,%
                    1.5/3/red,%
                    2/2.5/red,%
                    2/1/blue,%
                    2.5/2/blue,%
                    3/1/blue,%
                    3.5/0.8/blue,%
                    4/1.5/blue%
                } {%
                    \fill[\c!70] (\x,\y) circle (0.08);%
                }
            \end{tikzpicture}
            \vspace{0.2cm}
            \centering
            \\
            \textit{Centroides não mudaram significativamente: convergência alcançada}
        }
    \end{center}
\end{frame}

% Frame: K-médias - Resultado Final
\begin{frame}{K-médias: Resultado Final}
    \begin{itemize}
        \item \textbf{Clusters Definidos:} Os pontos foram agrupados com sucesso.
        \item \textbf{Centroides Estáveis:} O algoritmo convergiu.
    \end{itemize}
    \vspace{0.3cm}
    \begin{center}
        \begin{tikzpicture}[scale=0.9]
            % Plano cartesiano fixo
            \draw[step=1cm,gray,very thin] (0,0) grid (5,5);
            \draw[->] (0,0) -- (5.2,0) node[right] {$x$};
            \draw[->] (0,0) -- (0,5.2) node[above] {$y$};

            % Centroides finais
            \fill[red] (1.375,3.125) node[above] {\(\boldsymbol{\mu}_1\)} circle (0.12);
            \fill[blue] (3.2,1.16) node[right] {\(\boldsymbol{\mu}_2\)} circle (0.12);

            % Dados finais atribuídos
            \foreach \x/\y/\c in {%
                0.8/3.5/red,%
                1.2/4/red,%
                1.5/3/red,%
                2/2.5/red,%
                2/1/blue,%
                2.5/2/blue,%
                3/1/blue,%
                3.5/0.8/blue,%
                4/1.5/blue%
            } {%
                \fill[\c!70] (\x,\y) circle (0.08);%
            }
        \end{tikzpicture}
    \end{center}
\end{frame}





\begin{frame}{Resumo K-Means}
    \textbf{Algoritmo K-Means:}
    \begin{enumerate}
        \item Agrupa os dados em \(k\) grupos, onde \(k\) é predefinido.
        \item Seleciona \(k\) pontos aleatoriamente como centros de cluster (centróides).
        \item Atribui objetos ao centro de cluster mais próximo de acordo com a função de distância euclidiana.
        \item Calcula o centróide ou a média de todos os objetos em cada cluster.
        \item Repete as etapas 3 e 4 até que os mesmos pontos sejam atribuídos a cada cluster em rodadas consecutivas (convergência).
    \end{enumerate}
    \vspace{0.5cm}
    O K-Means é amplamente utilizado para agrupar dados e identificar padrões, separando-os em grupos homogêneos.
\end{frame}


\begin{frame}
    \centering
    \huge
    Um exemplo numérico
\end{frame}






% \begin{frame}{Selecionando Dados para o K-Means}
%     \textbf{Exemplo:}
%     \begin{itemize}
%         \item Queremos agrupar os visitantes de um site utilizando apenas a idade.
%         \item Os dados (idades dos visitantes) são:
%     \end{itemize}
%     \begin{block}{Dados}
%     \[
%     n = 19 \quad \text{(número de visitantes)}
%     \]
%     \[
%     15, 15, 16, 19, 19, 20, 20, 21, 22, 28, 35, 40, 41, 42, 43, 44, 60, 61, 65
%     \]
%     \end{block}
%     \vspace{0.5cm}
%     Nosso objetivo é dividir esses visitantes em 2 grupos (\(k = 2\)).
% \end{frame}

% \begin{frame}{Inicializando os Clusters}
%     \textbf{Passo 1: Escolher 2 centroides iniciais aleatoriamente.}
%     \begin{itemize}
%         \item Vamos escolher dois centroides iniciais com base em idades aleatórias ou médias:
%     \end{itemize}
%     \begin{block}{Inicialização dos Clusters}
%     \[
%     k = 2 \quad \text{(número de clusters)}
%     \]
%     \[
%     c_1 = 16 \quad \text{(centroide do cluster 1)}
%     \]
%     \[
%     c_2 = 22 \quad \text{(centroide do cluster 2)}
%     \]
%     \end{block}
% \end{frame}

% \begin{frame}{Cálculo da Distância Euclidiana}
%     \textbf{Função de Distância Euclidiana:}
%     \begin{block}{Fórmula Geral}
%     \[
%     d = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}
%     \]
%     \end{block}
%     \vspace{0.5cm}
%     \begin{itemize}
%         \item Como estamos lidando com um espaço unidimensional (somente idades), a fórmula se simplifica para:
%     \end{itemize}
%     \begin{block}{Fórmula Unidimensional}
%     \[
%     d = |x_2 - x_1|
%     \]
%     \end{block}
%     Aqui, \(x_1\) e \(x_2\) são as idades dos visitantes e os centroides, respectivamente.
% \end{frame}

% \begin{frame}{Atribuindo ao Cluster Mais Próximo}
%     \textbf{Passo 2: Atribuir cada ponto ao cluster mais próximo.}
%     \begin{itemize}
%         \item Após calcular a distância entre cada visitante e os centroides, atribuímos o visitante ao cluster cujo centroide estiver mais próximo.
%     \end{itemize}
%     \vspace{0.5cm}
%     \begin{block}{Exemplo de Atribuição}
%     \begin{itemize}
%         \item Idade: 15
%         \item Distância ao \(c_1 = |15 - 16| = 1\)
%         \item Distância ao \(c_2 = |15 - 22| = 7\)
%         \item Resultado: O visitante é atribuído ao cluster 1 (\(c_1\)).
%     \end{itemize}
%     \end{block}
%     \vspace{0.5cm}
%     Repetimos este processo para todos os visitantes.
% \end{frame}






\begin{frame}{Iteração 1 - Inicializando os Centroides}
    \textbf{Exemplo:} Suponha que temos os seguintes dados de idade:

    \begin{block}{Dados}
    \[
    15, 15, 16, 19, 19, 20, 20, 21, 22, 28, 35, 40, 41, 42, 43, 44, 60, 61, 65
    \]
    \end{block}

    Inicializamos dois centroides aleatórios:
    \[
    c_1 = 16, \quad c_2 = 22
    \]

    Agora vamos calcular as distâncias para cada ponto e atribuí-los aos clusters.
\end{frame}


\begin{frame}{Iteração 1 - Atribuindo ao Cluster Mais Próximo}
    \textbf{Passo 1:} Calculando as distâncias e atribuindo os pontos.

    \begin{itemize}
        \item Para \(x = 15\):
        \[
        d(x, c_1) = |15 - 16| = 1 \quad d(x, c_2) = |15 - 22| = 7
        \]
        \item O ponto \(15\) será atribuído ao cluster 1 (\(c_1\)).
    \end{itemize}

    \begin{itemize}
        \item Repetimos este processo para todos os pontos...
    \end{itemize}

    \only<2>{
        \textbf{Resultado da Atribuição na Iteração 1:}
        \begin{block}{Clusters}
        Cluster 1 (\(c_1 = 16\)): 15, 15, 16, 19, 19, 20, 20, 21 \\
        Cluster 2 (\(c_2 = 22\)): 22, 28, 35, 40, 41, 42, 43, 44, 60, 61, 65
        \end{block}
    }
\end{frame}


\begin{frame}{Iteração 1 - Atualizando os Centroides}
    \textbf{Passo 2:} Atualizando os centroides.

    Calculamos a média dos pontos atribuídos a cada cluster para determinar os novos centroides:

    \[
    \text{Novo } c_1 = \frac{15 + 15 + 16 + 19 + 19 + 20 + 20 + 21}{8} = 18
    \]
    \[
    \text{Novo } c_2 = \frac{22 + 28 + 35 + 40 + 41 + 42 + 43 + 44 + 60 + 61 + 65}{11} = 43
    \]

    Os novos centroides para a próxima iteração são:
    \[
    c_1 = 18, \quad c_2 = 43
    \]
\end{frame}


\begin{frame}{Iteração 2 - Atribuindo ao Cluster Mais Próximo}
    \textbf{Iteração 2:} Atribuindo os pontos aos novos centroides.

    Vamos repetir o cálculo de distâncias com os novos centroides (\(c_1 = 18\) e \(c_2 = 43\)):

    \begin{itemize}
        \item Para \(x = 15\):
        \[
        d(x, c_1) = |15 - 18| = 3 \quad d(x, c_2) = |15 - 43| = 28
        \]
        \item O ponto \(15\) ainda será atribuído ao cluster 1 (\(c_1\)).
    \end{itemize}

    \only<2>{
        \textbf{Resultado da Atribuição na Iteração 2:}
        \begin{block}{Clusters}
        Cluster 1 (\(c_1 = 18\)): 15, 15, 16, 19, 19, 20, 20, 21, 22, 28 \\
        Cluster 2 (\(c_2 = 43\)): 35, 40, 41, 42, 43, 44, 60, 61, 65
        \end{block}
    }
\end{frame}


\begin{frame}{Iteração 2 - Atualizando os Centroides}
    \textbf{Passo 2:} Atualizando os centroides.

    Calculamos novamente a média dos pontos para atualizar os centroides:

    \[
    \text{Novo } c_1 = \frac{15 + 15 + 16 + 19 + 19 + 20 + 20 + 21 + 22 + 28}{10} = 19.5
    \]
    \[
    \text{Novo } c_2 = \frac{35 + 40 + 41 + 42 + 43 + 44 + 60 + 61 + 65}{9} = 47.88
    \]

    Os novos centroides para a próxima iteração são:
    \[
    c_1 = 19.5, \quad c_2 = 47.88
    \]

    Repetimos esse processo até que os centroides parem de mudar significativamente (convergência).
\end{frame}





\begin{frame}
    \centering
    \huge
    Google Colab\\


    \small
    http://u.acilab.com.br/WP
        
\end{frame}









\begin{frame}
    \centering
    \huge
    Implementação em Python 
\end{frame}

% Slide: Etapas do Algoritmo K-Means
\begin{frame}{Etapas do Algoritmo K-Means}
    \begin{enumerate}
        \item \textbf{Inicialização dos Centroides:}
        \begin{itemize}
            \item Selecionar aleatoriamente \( k \) pontos do conjunto de dados como os centroides iniciais.
            \item Função relevante: \texttt{inicializar\_centroides}
        \end{itemize}

        \vspace{0.3cm}

        \item \textbf{Cálculo das Distâncias:}
        \begin{itemize}
            \item Calcular a distância euclidiana entre cada ponto e os centroides.
            \item Função relevante: \texttt{distancia}
        \end{itemize}

        \vspace{0.3cm}

        \item \textbf{Atribuição aos Clusters:}
        \begin{itemize}
            \item Atribuir cada ponto ao cluster cujo centróide esteja mais próximo.
            \item Função relevante: \texttt{fit} (parte que atribui rótulos)
        \end{itemize}

        \vspace{0.3cm}

        \item \textbf{Atualização dos Centroides:}
        \begin{itemize}
            \item Atualizar os centroides, calculando a média dos pontos pertencentes a cada cluster.
            \item Função relevante: \texttt{updateCenters}
        \end{itemize}

        \vspace{0.3cm}

        \item \textbf{Verificação da Convergência:}
        \begin{itemize}
            \item Verificar se os centroides pararam de mudar. Se sim, o algoritmo é interrompido.
            \item Função relevante: Lógica interna do \texttt{fit}
        \end{itemize}

        \vspace{0.3cm}

        \item \textbf{Classificação de Novos Pontos:}
        \begin{itemize}
            \item Após o treinamento, atribuir novos pontos ao cluster mais próximo usando os centroides finais.
            \item Função relevante: \texttt{predict}
        \end{itemize}
    \end{enumerate}
\end{frame}


% Frame: Implementação do KMeans - Inicialização
\begin{frame}[fragile]{Implementação do KMeans - Inicialização}
\begin{lstlisting}[language=Python]
class Kmeans:
    def __init__(self, k=2):
        self.k = k
        self.centroids = []
\end{lstlisting}
    \vspace{0.3cm}
    \begin{itemize}
        \item A função \texttt{init} inicializa o número de clusters \( k \) e uma lista vazia para armazenar os centroides.
    \end{itemize}
\end{frame}

% Frame: Implementação do KMeans - Cálculo da Distância
\begin{frame}[fragile]{Implementação do KMeans - Cálculo da Distância}
\begin{lstlisting}[language=Python]
    def distancia(self, x1, x2):
        return np.sqrt(np.sum((x1 - x2)**2))
\end{lstlisting}
    \vspace{0.3cm}
    \begin{itemize}
        \item A função \texttt{distancia} calcula a distância euclidiana entre dois pontos \( x1 \) e \( x2 \).
    \end{itemize}
    \vspace{0.3cm}
    \begin{itemize}
        \item \textbf{Fórmula da Distância Euclidiana:}
        \[
        d(\mathbf{x}_i, \mathbf{\mu}_j) = \sqrt{\sum_{l=1}^{m} (x_{il} - \mu_{jl})^2}
        \]
        onde:
        \begin{itemize}
            \item \( x_{il} \) é o \( l \)-ésimo componente do ponto \( \mathbf{x}_i \).
            \item \( \mu_{jl} \) é o \( l \)-ésimo componente do centroide \( \mathbf{\mu}_j \).
        \end{itemize}
    \end{itemize}
\end{frame}

% Frame: Implementação do KMeans - Atualização dos Centroides
\begin{frame}[fragile]{Implementação do KMeans - Atualização dos Centroides}
\begin{lstlisting}[language=Python]
    def updateCenters(self, x, y):
        new_clusters = []
        for i in range(self.k):
            indices = np.where(np.array(y) == i)
            new_clusters.append(np.mean(np.array(x)[indices], axis=0))
        return new_clusters
\end{lstlisting}
    \vspace{0.3cm}
    \begin{itemize}
        \item A função \texttt{updateCenters} recalcula os centroides como a média dos pontos atribuídos a cada cluster.
    \end{itemize}
    \vspace{0.3cm}
    \begin{itemize}
        \item \textbf{Fórmula para Atualização do Centroide:}
        \[
        \mathbf{\mu}_j = \frac{1}{|C_j|} \sum_{\mathbf{x}_i \in C_j} \mathbf{x}_i
        \]
        onde:
        \begin{itemize}
            \item \( \mathbf{\mu}_j \) é o centroide do cluster \( j \).
            \item \( C_j \) é o conjunto de pontos atribuídos ao cluster \( j \).
            \item \( |C_j| \) é o número de pontos no cluster \( j \).
        \end{itemize}
    \end{itemize}
\end{frame}

% Frame: Implementação do KMeans - Algoritmo de Treinamento (Fit)
\begin{frame}[fragile]{Algoritmo de Treinamento (Fit)}
\begin{lstlisting}[language=Python]
    def fit(self, x, para_em=10):
        # Inicializa os centróides aleatoriamente
        self.centroids = x[np.random.randint(0, len(x), self.k)]
        count = 0
        while True:
            y = []
            # Atribui cada ponto ao centróide mais próximo
            for i in range(len(x)):
                distancias = [self.distancia(x[i], centroid) for centroid in self.centroids]
                y.append(np.argmin(distancias))
            self.centroids = self.updateCenters(x, y)

            if count > para_em:
                break
            count += 1
        return y
\end{lstlisting}
    \vspace{0.3cm}
    \begin{itemize}
        \item A função \texttt{fit} é responsável pelo treinamento do modelo. 
        %Ela inicializa os centroides, calcula as distâncias e atualiza os clusters até atingir o número máximo de iterações ou convergir.
    \end{itemize}
\end{frame}

% Frame: Predição de Clusters
\begin{frame}[fragile]{Predição de Clusters}
\begin{lstlisting}[language=Python]
def predict(self,x):
    distancias = [self.distancia(x, centroid) for centroid in self.centroids]
    return np.argmax(distancias)
\end{lstlisting}
    \vspace{0.3cm}
    \begin{itemize}
        \item A função \texttt{predict} recebe um novo ponto \( x \) e retorna o cluster ao qual esse ponto pertence, baseado na distância aos centroides.
    \end{itemize}
    \vspace{0.3cm}
    \begin{itemize}
        \item \textbf{Fórmula da Decisão:}
        \[
        \text{Cluster}(x) = \arg\min_{j} \{d(\mathbf{x}, \mathbf{\mu}_j)\}
        \]
        onde \( d(\mathbf{x}, \mathbf{\mu}_j) \) é a distância entre o ponto \( \mathbf{x} \) e o centroide \( \mathbf{\mu}_j \).
    \end{itemize}
\end{frame}


% % Frame: Implementação do K-médias em Python
% \begin{frame}[fragile]{Implementação do K-médias em Python}
%     \begin{itemize}
%         \item A seguir, apresentamos uma implementação do algoritmo K-médias em Python.
%         \item Cada função representa uma etapa do algoritmo com suas respectivas fórmulas.
%     \end{itemize}
% \end{frame}

% % Frame: Inicialização dos Centroides
% \begin{frame}[fragile]{Inicialização dos Centroides}
%     \begin{block}{Função \texttt{inicializar\_centroides}}
% \begin{lstlisting}[language=Python]
% def inicializar_centroides(X, k):
%     """
%     Inicializa aleatoriamente os centroides a partir dos dados.
%     """
%     indices = np.random.choice(X.shape[0], k, replace=False)
%     centroides = X[indices]
%     return centroides
% \end{lstlisting}
%     \end{block}
%     \vspace{0.3cm}
%     \begin{itemize}
%         \item \textbf{Parâmetros:}
%         \begin{itemize}
%             \item \( X \): Dados de entrada.
%             \item \( k \): Número de clusters.
%         \end{itemize}
%         \item \textbf{Descrição:}
%         \begin{itemize}
%             \item Seleciona aleatoriamente \( k \) pontos de \( X \) como centroides iniciais.
%         \end{itemize}
%     \end{itemize}
% \end{frame}

% % Frame: Cálculo das Distâncias
% \begin{frame}[fragile]{Cálculo das Distâncias}
%     \begin{block}{Função \texttt{calcular\_distancias}}
% \begin{lstlisting}[language=Python]
% def calcular_distancias(X, centroides):
%     """
%     Calcula a distância euclidiana entre cada ponto e cada centroide.
%     """
%     distancias = np.linalg.norm(X[:, np.newaxis] - centroides, axis=2)
%     return distancias
% \end{lstlisting}
%     \end{block}
%     \vspace{0.3cm}
%     \begin{itemize}
%         \item \textbf{Fórmula:}
%         \[
%         d(\mathbf{x}_i, \boldsymbol{\mu}_j) = \sqrt{\sum_{l=1}^{m} (x_{il} - \mu_{jl})^2}
%         \]
%         \item \textbf{Descrição:}
%         \begin{itemize}
%             \item Calcula a distância euclidiana entre cada ponto \( \mathbf{x}_i \) e cada centroide \( \boldsymbol{\mu}_j \).
%         \end{itemize}
%     \end{itemize}
% \end{frame}

% % Frame: Atribuição aos Clusters
% \begin{frame}[fragile]{Atribuição aos Clusters}
%     \begin{block}{Função \texttt{atribuir\_clusters}}
% \begin{lstlisting}[language=Python]
% def atribuir_clusters(distancias):
%     """
%     Atribui cada ponto ao cluster do centroide mais próximo.
%     """
%     rótulos = np.argmin(distancias, axis=1)
%     return rótulos
% \end{lstlisting}
%     \end{block}
%     \vspace{0.3cm}
%     \begin{itemize}
%         \item \textbf{Descrição:}
%         \begin{itemize}
%             \item Para cada ponto, identifica o índice do centroide mais próximo.
%             \item Atribui o ponto ao cluster correspondente.
%         \end{itemize}
%     \end{itemize}
% \end{frame}

% % Frame: Atualização dos Centroides
% \begin{frame}[fragile]{Atualização dos Centroides}
%     \begin{block}{Função \texttt{atualizar\_centroides}}
% \begin{lstlisting}[language=Python]
% def atualizar_centroides(X, rótulos, k):
%     """
%     Atualiza os centroides calculando a média dos pontos atribuídos a cada cluster.
%     """
%     centroides = np.array([X[rótulos == i].mean(axis=0) for i in range(k)])
%     return centroides
% \end{lstlisting}
%     \end{block}
%     \vspace{0.3cm}
%     \begin{itemize}
%         \item \textbf{Fórmula:}
%         \[
%         \boldsymbol{\mu}_j = \frac{1}{|C_j|} \sum_{\mathbf{x}_i \in C_j} \mathbf{x}_i
%         \]
%         \item \textbf{Descrição:}
%         \begin{itemize}
%             \item Calcula a média dos pontos em cada cluster para atualizar o centroide.
%         \end{itemize}
%     \end{itemize}
% \end{frame}

% % Frame: Verificação da Convergência
% \begin{frame}[fragile]{Verificação da Convergência}
%     \begin{block}{Função \texttt{verificar\_convergencia}}
% \begin{lstlisting}[language=Python]
% def verificar_convergencia(centroides_antigos, centroides, tol=1e-4):
%     """
%     Verifica se os centroides convergiram.
%     """
%     deslocamento = np.linalg.norm(centroides - centroides_antigos, axis=1)
%     return np.all(deslocamento < tol)
% \end{lstlisting}
%     \end{block}
%     \vspace{0.3cm}
%     \begin{itemize}
%         \item \textbf{Critério:}
%         \[
%         \|\boldsymbol{\mu}_j^{(t)} - \boldsymbol{\mu}_j^{(t-1)}\| < \epsilon
%         \]
%         \item \textbf{Descrição:}
%         \begin{itemize}
%             \item Calcula o deslocamento de cada centroide.
%             \item Verifica se todos os deslocamentos são menores que a tolerância \( \epsilon \).
%         \end{itemize}
%     \end{itemize}
% \end{frame}

% % Frame: Iteração do Algoritmo
% \begin{frame}[fragile]{Iteração do Algoritmo K-médias}
%     \begin{block}{Função \texttt{k\_means}}
% \begin{lstlisting}[language=Python]
% def k_means(X, k, max_iter=100):
%     """
%     Executa o algoritmo K-médias nos dados X.
%     """
%     centroides = inicializar_centroides(X, k)
%     for _ in range(max_iter):
%         centroides_antigos = centroides.copy()
%         distancias = calcular_distancias(X, centroides)
%         rótulos = atribuir_clusters(distancias)
%         centroides = atualizar_centroides(X, rótulos, k)
%         if verificar_convergencia(centroides_antigos, centroides):
%             break
%     return centroides, rótulos
% \end{lstlisting}
%     \end{block}
%     \vspace{0.3cm}
%     \begin{itemize}
%         \item \textbf{Descrição:}
%         \begin{itemize}
%             \item Combina todas as etapas anteriores.
%             \item Itera até a convergência ou até atingir o número máximo de iterações.
%         \end{itemize}
%     \end{itemize}
% \end{frame}

% % Frame: Exemplo de Uso
% \begin{frame}[fragile]{Exemplo de Uso}
%     \begin{block}{Código de Exemplo}
% \begin{lstlisting}[language=Python]
% X = np.array([# Dados de exemplo
%     [0.5, 3.5],
%     [1.0, 4.0],
%     [1.5, 3.0],
%     [2.0, 2.5],
%     [2.0, 1.0],
%     [2.5, 2.0],
%     [3.0, 1.0],
%     [3.5, 0.5],
%     [4.0, 1.5],
% ])

% k = 2  # Número de clusters
% centroides, rótulos = k_means(X, k)# Executar K-means
% print("Centroides finais:")
% print(centroides)
% print("\nRótulos dos clusters:")
% print(rótulos)
% \end{lstlisting}
%     \end{block}
%     % \vspace{0.3cm}
%     % \begin{itemize}
%     %     \item \textbf{Descrição:}
%     %     \begin{itemize}
%     %         \item Aplica o algoritmo K-médias ao conjunto de dados de exemplo.
%     %         \item Exibe os centroides finais e os rótulos dos clusters.
%     %     \end{itemize}
%     % \end{itemize}
% \end{frame}

% % Frame: Resultados do Exemplo
% \begin{frame}[fragile]{Resultados do Exemplo}
%     \begin{block}{Saída Esperada}
% \begin{verbatim}
% Centroides finais:
% [[1.375 3.125]
%  [3.2   1.16 ]]

% Rótulos dos clusters:
% [0 0 0 0 1 1 1 1 1]
% \end{verbatim}
%     \end{block}
%     \vspace{0.3cm}
%     \begin{itemize}
%         \item \textbf{Interpretação:}
%         \begin{itemize}
%             \item Os pontos foram agrupados em dois clusters.
%             \item Os centroides representam o centro de cada cluster.
%         \end{itemize}
%     \end{itemize}
% \end{frame}




\begin{frame}
    \centering
    \huge
    Avaliação de Desempenho em Clustering
\end{frame}


% Frame: Avaliação de Desempenho em Clustering
\begin{frame}{Avaliação de Desempenho em Clustering}
    \begin{itemize}
        \item \textbf{Desafio:} Avaliar a qualidade dos clusters obtidos sem os rótulos verdadeiros.
        \item \textbf{Objetivos da Avaliação:}
        \begin{itemize}
            \item Medir a \textbf{coerência interna} dos clusters (compactação).
            \item Medir a \textbf{separação} entre clusters distintos.
        \end{itemize}
        \item \textbf{Métricas Comuns:}
        \begin{itemize}
            \item Soma dos Quadrados Dentro dos Clusters (\textbf{Within-Cluster Sum of Squares - WCSS}).
            \item Coeficiente de Silhueta (\textbf{Silhouette Coefficient}).
            % \item Índice de Davies-Bouldin.
            % \item Índice de Calinski-Harabasz.
        \end{itemize}
    \end{itemize}
\end{frame}

% Frame: Soma dos Quadrados Dentro dos Clusters (WCSS)
\begin{frame}{Soma dos Quadrados Dentro dos Clusters (WCSS)}
    \begin{itemize}
        \item \textbf{Definição:} Mede a variabilidade dos pontos dentro de cada cluster.
        \item \textbf{Fórmula:}
        \[
        \text{WCSS} = \sum_{j=1}^{k} \sum_{\mathbf{x}_i \in C_j} \|\mathbf{x}_i - \boldsymbol{\mu}_j\|^2
        \]
        \item \textbf{Interpretação:} Valores menores indicam clusters mais compactos.
    \end{itemize}
    \vspace{0.3cm}
    % \begin{center}
    %     \includegraphics[width=0.6\textwidth]{elbow_method.png}
    % \end{center}
\end{frame}

% Frame: Método do Cotovelo (Elbow Method)
\begin{frame}{Método do Cotovelo}
    \begin{itemize}
        \item \textbf{Objetivo:} Determinar o número ideal de clusters \( k \).
        \item \textbf{Procedimento:}
        \begin{enumerate}
            \item Executar o algoritmo K-médias para diferentes valores de \( k \).
            \item Calcular o WCSS para cada \( k \).
            \item Plotar o WCSS em função de \( k \).
        \end{enumerate}
        \item \textbf{Interpretação:} O ponto onde a redução do WCSS começa a se estabilizar (cotovelo) indica o número ideal de clusters.
    \end{itemize}
    \vspace{0.2cm}
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[
                xlabel={Número de Clusters \( k \)},
                ylabel={WCSS},
                xmin=1, xmax=10,
                ymin=0, ymax=100,
                xtick={1,2,...,10},
                ytick={0,20,...,100},
                legend pos=north east,
                ymajorgrids=true,
                grid style=dashed,
                width=0.8\textwidth,
                height=5cm,
            ]
            \addplot[
                color=blue,
                mark=*,
                ]
                coordinates {
                (1, 90)
                (2, 70)
                (3, 50)
                (4, 40)
                (5, 35)
                (6, 30)
                (7, 28)
                (8, 27)
                (9, 26)
                (10,25)
                };
            \end{axis}
        \end{tikzpicture}
    \end{center}
\end{frame}

% Frame: Coeficiente de Silhueta
\begin{frame}{Coeficiente de Silhueta}
    \begin{itemize}
        \item \textbf{Definição:} Avalia a qualidade do agrupamento considerando a coesão e separação.
        \item \textbf{Fórmula para um ponto \( \mathbf{x}_i \):}
        \[
        s_i = \frac{b_i - a_i}{\max\{a_i, b_i\}}
        \]
        onde:
        \begin{itemize}
            \item \( a_i \): Distância média entre \( \mathbf{x}_i \) e os outros pontos do mesmo cluster.
            \item \( b_i \): Distância média entre \( \mathbf{x}_i \) e os pontos do cluster mais próximo.
        \end{itemize}
        \item \textbf{Interpretação:}
        \begin{itemize}
            \item \( -1 \leq s_i \leq 1 \).
            \item Valores próximos a 1 indicam que o ponto está bem inserido no cluster.
            \item Valores próximos a -1 indicam possível má classificação.
        \end{itemize}
    \end{itemize}
\end{frame}

% Frame: Exemplo do Coeficiente de Silhueta
\begin{frame}{Exemplo do Coeficiente de Silhueta}
    \begin{itemize}
        \item \textbf{Gráfico de Silhueta:} Mostra a distribuição dos valores de silhueta para cada cluster.
        \item \textbf{Uso:} Auxilia na avaliação do número de clusters e na identificação de pontos mal agrupados.
    \end{itemize}
    % \vspace{0.3cm}
    \begin{center}
        \begin{tikzpicture}
            \begin{axis}[
                xbar,
                xmin=-0.2, xmax=1,
                xlabel={Coeficiente de Silhueta},
                ylabel={Pontos de Dados},
                ytick={1,2,3,4,5,6,7,8,9,10},
                yticklabels={
                    $P_{10}$,
                    $P_{9}$,
                    $P_{8}$,
                    $P_{7}$,
                    $P_{6}$,
                    $P_{5}$,
                    $P_{4}$,
                    $P_{3}$,
                    $P_{2}$,
                    $P_{1}$
                },
                yticklabel style={font=\small},
                width=0.8\textwidth,
                height=6cm,
                bar width=8pt,
                enlarge y limits=0.05,
                enlarge x limits=0.02,
                axis x line=bottom,
                axis y line=left,
                legend style={at={(0.5,-0.15)},anchor=north,legend columns=-1},
                ]
    
                % Cluster 1
                \addplot+[
                    bar shift=0pt,
                    fill=red!70,
                    draw=none,
                ] coordinates {
                    (0.85,10)
                    (0.80,9)
                    (0.75,8)
                    (0.70,7)
                    (0.65,6)
                };
    
                % Cluster 2
                \addplot+[
                    bar shift=0pt,
                    fill=blue!70,
                    draw=none,
                ] coordinates {
                    (0.90,5)
                    (0.88,4)
                    (0.85,3)
                    (0.80,2)
                    (0.78,1)
                };
    
                \legend{Cluster 1, Cluster 2}
            \end{axis}
        \end{tikzpicture}
    \end{center}
\end{frame}














\end{document}
